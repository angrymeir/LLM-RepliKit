# LLM-RepliKit

[![DOI](https://zenodo.org/badge/987031008.svg)](https://doi.org/10.5281/zenodo.17589277)

RepliKit is a framework to reproduce experimental software studies.
It is built to reproduce LLM studies, but can also be employed for other experimental software studies.

> [!tip]
> This repository uses [Git Large File Storage (LFS)](https://git-lfs.com). Please install git-LFS before cloning this repository, e.g., using `git install lfs` or `brew install git-lfs`.

## How to get started

Check out the [replikit directory](replikit/) for guidance on how to replicate studies.

## Reproduction results

| Success | ID | Title | DOI |
|------ | ----- | ------ | ------ |
| ❌ |[main2](replikit/studies/main2/)| CrashTranslator: Automatically Reproducing Mobile Application: Crashes Directly from Stack Trace | [10.1145/3597503.3623298](https://doi.org/10.1145/3597503.3623298) |
| ❌ | main4 | CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models | [10.1145/3597503.3623316](https://doi.org/10.1145/3597503.3623316) |
| ❌ | main8 | Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors | [10.1145/3597503.3608132](https://doi.org/10.1145/3597503.3608132) |
| ❌ | main11 | Rust-lancet: Automated Ownership-Rule-Violation Fixing with Behavior Preservation | [10.1145/3597503.3639103](https://doi.org/10.1145/3597503.3639103) |
| ❌ | [main12](replikit/studies/009/) | Lost in Translation: A Study of Bugs Introduced by Large Language Models while Translating Code | [10.1145/3597503.3639226](https://doi.org/10.1145/3597503.3639226) |
| ❌ | main14 | ChatGPT Incorrectness Detection in Software Reviews | [10.1145/3597503.3639194](https://doi.org/10.1145/3597503.3639194) |
| ❌ |[main19](replikit/studies/main19/)| Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning| [10.1145/3597503.3608134](https://doi.org/10.1145/3597503.3608134) |
| ❌ | main40 | PyTy: Repairing Static Type Errors in Python | [10.1145/3597503.3639184](https://doi.org/10.1145/3597503.3639184) |
| ❌ | [main41](replikit/studies/main41) | Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization) | [10.1145/3597503.3639183](https://doi.org/10.1145/3597503.3639183) | 
| ❌ | nier6 | Exploring ChatGPT for Toxicity Detection in GitHub | [10.1145/3639476.3639777](https://doi.org/10.1145/3639476.3639777) |
| ❌ | [nier7](replikit/studies/002/) | Re(gEx\|DoS)Eval: Evaluating Generated Regular Expressions and their Proneness to DoS Attacks | [10.1145/3639476.3639757](https://doi.org/10.1145/3639476.3639757) |
| ✅ | [nier9](replikit/studies/007) | Large Language Model for Vulnerability Detection: Emerging Results and Future Directions | [10.1145/3639476.3639762](https://doi.org/10.1145/3639476.3639762) |
| ❌ | [seis2](replikit/studies/003) | An Empirical Study on Compliance with Ranking Transparency in the Software Documentation of EU Online Platforms | [10.1145/3639475.3640112](https://doi.org/10.1145/3639475.3640112) |
| ❌ | ASE main1 | PatUntrack: Automated Generating Patch Examples for Issue Reports without Tracked Insecure Code | [10.1145/3691620.3694982](https://doi.org/10.1145/3691620.3694982) | 
| ✅ | [ASE main5](replikit/studies/005) | Demonstration-Free: Towards More Practical Log Parsing with Large Language Models | [10.1145/3691620.3694994](https://doi.org/10.1145/3691620.3694994) |
| ❌ | ASE main21 | FAIL: Analyzing Software Failures from the News Using LLMs | [10.1145/3691620.3695022](https://doi.org/10.1145/3691620.3695022) |
| ❌ | ASE main22 | Detecting and Explaining Anomalies Caused byWeb Tamper Attacks via Building Consistency-based Normality | [10.1145/3691620.3695024](https://doi.org/10.1145/3691620.3695024) |
| ❌ | ASE main26 | Semantic Sleuth: Identifying Ponzi Contracts via Large Language Models | [10.1145/3691620.3695055](https://doi.org/10.1145/3691620.3695055) |
